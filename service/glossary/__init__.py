# lightVT/service/glossary/__init__.py
"""
æœ¯è¯­è¡¨ç®¡ç†æ¨¡å—
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from ..log import get_logger
from toolz import keyfilter, pipe
import utils

logger = get_logger("Glossary")
glossary: Dict[str, str] = {}

def load_glossary(filename: str):
    """åŠ è½½æœ¯è¯­è¡¨"""
    global glossary
    try:
        glossary_path = Path(f"cache/{filename}")
        if glossary_path.exists():
            with open(glossary_path, 'r', encoding='utf-8') as f:
                glossary = json.load(f)
                logger.info(f"å·²åŠ è½½æœ¯è¯­è¡¨ï¼ŒåŒ…å« {len(glossary)} ä¸ªæœ¯è¯­")
        else:
            glossary = {}
            logger.info("æœªæ‰¾åˆ°æœ¯è¯­è¡¨æ–‡ä»¶ï¼Œåˆ›å»ºæ–°çš„æœ¯è¯­è¡¨")
    except Exception as e:
        logger.error(f"åŠ è½½æœ¯è¯­è¡¨å¤±è´¥: {e}")
        glossary = {}

def save_glossary(filename:str):
    """ä¿å­˜æœ¯è¯­è¡¨"""
    try:
        global glossary
        glossary_path = Path(f"cache/{filename}")
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        glossary_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(glossary_path, 'w', encoding='utf-8') as f:
            json.dump(glossary, f, ensure_ascii=False, indent=2)
        logger.info(f"æœ¯è¯­è¡¨å·²ä¿å­˜ï¼ŒåŒ…å« {len(glossary)} ä¸ªæœ¯è¯­")
    except Exception as e:
        logger.error(f"ä¿å­˜æœ¯è¯­è¡¨å¤±è´¥: {e}")

def add_term(source_term: str, target_term: str):
    """æ·»åŠ æœ¯è¯­"""
    global glossary
    glossary[source_term.strip()] = target_term.strip()

def remove_term(source_term: str):
    """åˆ é™¤æœ¯è¯­"""
    global glossary
    if source_term in glossary:
        del glossary[source_term]

def get_terms() -> Dict[str, str]:
    """è·å–æ‰€æœ‰æœ¯è¯­"""
    global glossary
    return glossary.copy()

def clear_glossary():
    """æ¸…ç©ºæœ¯è¯­è¡¨"""
    global glossary
    glossary.clear()

def apply_glossary_to_text( text: str) -> str:
    """å°†æœ¯è¯­è¡¨åº”ç”¨åˆ°æ–‡æœ¬ä¸­"""
    global glossary
    if not glossary:
        return text
    
    # æŒ‰æœ¯è¯­é•¿åº¦æ’åºï¼Œä¼˜å…ˆæ›¿æ¢é•¿æœ¯è¯­
    sorted_terms = sorted(glossary.items(), key=lambda x: len(x[0]), reverse=True)

    result = text
    for source_term, target_term in sorted_terms:
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œç²¾ç¡®åŒ¹é…ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…
        pattern = r'\b' + re.escape(source_term) + r'\b'
        result = re.sub(pattern, target_term, result, flags=re.IGNORECASE)
    
    return result

def generate_glossary_prompt(source_text:str) -> str:
    """ç”ŸæˆåŒ…å«æœ¯è¯­è¡¨çš„æç¤ºè¯"""
    global glossary
    if not glossary:
        return ""
    
    source_glossary = keyfilter(lambda k: k in source_text.lower(), glossary)
    
    if not source_glossary or len(source_glossary) == 0:
        return ""

    terms_text = "\n".join([f"- {source} â†’ {target}" for source, target in source_glossary.items()])

    return f"""
ã€æœ¯è¯­è¡¨ã€‘
{terms_text}
"""

def is_empty() -> bool:
    """æ£€æŸ¥æœ¯è¯­è¡¨æ˜¯å¦ä¸ºç©º"""
    global glossary
    return len(glossary) == 0

def generate_from_subtitle_text(subtitle_text: str, target_language: str, model_path: str, n_gpu_layers: int = -1) -> Dict[str, str]:
    """ä»å­—å¹•æ–‡æœ¬æ™ºèƒ½ç”Ÿæˆæœ¯è¯­è¡¨"""
    try:
        from service.glossary.ai_generator import generate_glossary_from_subtitle, ExtractionConfig
        
        # ğŸ”¥ ç®€åŒ–è°ƒç”¨ï¼Œä¸éœ€è¦ä¼ å…¥ç¿»è¯‘å‡½æ•°
        config = ExtractionConfig(
            chunk_size=1000,          # æ¯ç‰‡æ®µ2000å­—ç¬¦
            min_term_frequency=2,     # æœ€å°‘å‡ºç°2æ¬¡
            max_terms_per_chunk=15,   # æ¯ç‰‡æ®µæœ€å¤š15ä¸ªæœ¯è¯­
            min_term_length=3,        # æœ€å°é•¿åº¦3ä¸ªå­—ç¬¦
            max_term_length=50        # æœ€å¤§é•¿åº¦50ä¸ªå­—ç¬¦
        )
        
        # ğŸ”¥ ç›´æ¥è°ƒç”¨ï¼Œå†…éƒ¨å¤„ç†ç¿»è¯‘
        generated_glossary = generate_glossary_from_subtitle(
            subtitle_text, 
            target_language, 
            model_path,
            n_gpu_layers=n_gpu_layers,
            config=config
        )
        
        logger.info(f"ä»å­—å¹•æ–‡æœ¬ç”Ÿæˆæœ¯è¯­è¡¨å®Œæˆï¼Œå…± {len(generated_glossary)} ä¸ªæœ¯è¯­")
        return generated_glossary
        
    except Exception as e:
        logger.error(f"ä»å­—å¹•æ–‡æœ¬ç”Ÿæˆæœ¯è¯­è¡¨å¤±è´¥: {e}")
        return {}
    
def to_glossary_filename(file_path:str) -> str:
    """å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºæœ¯è¯­è¡¨æ–‡ä»¶å"""
    return pipe(file_path,
                utils.get_filename, 
                utils.string_to_base64)